"""
VAE avec LSTM pour s√©ries temporelles.
Architecture adapt√©e aux workloads temporels.
"""

import torch
import torch.nn as nn
from typing import List, Tuple

class LSTMVAE(nn.Module):
    """
    VAE bas√© sur LSTM pour s√©ries temporelles.
    
    Architecture:
        Encoder: LSTM ‚Üí Dense ‚Üí (Œº, log_œÉ¬≤)
        Decoder: Dense ‚Üí LSTM ‚Üí Dense ‚Üí Reconstruction
    """
    
    def __init__(
        self,
        input_size: int = 1,
        sequence_length: int = 288,
        hidden_size: int = 128,
        latent_dim: int = 32,
        num_layers: int = 2,
        dropout: float = 0.2,
        bidirectional: bool = False
    ):
        """
        Args:
            input_size: Nombre de features par timestep (1 pour univari√©)
            sequence_length: Longueur de la s√©quence
            hidden_size: Taille des couches cach√©es LSTM
            latent_dim: Dimension de l'espace latent
            num_layers: Nombre de couches LSTM
            dropout: Taux de dropout
            bidirectional: Utiliser LSTM bidirectionnel
        """
        super().__init__()
            
        self.input_size = input_size
        self.sequence_length = sequence_length
        self.hidden_size = hidden_size
        self.latent_dim = latent_dim
        self.num_layers = num_layers
        self.bidirectional = bidirectional
        self.num_directions = 2 if bidirectional else 1
        
        # ============= ENCODER =============
        self.encoder_lstm = nn.LSTM(
            input_size=input_size,
            hidden_size=hidden_size,
            num_layers=num_layers,
            batch_first=True,
            dropout=dropout if num_layers > 1 else 0,
            bidirectional=bidirectional
        )
        
        # Couches pour Œº et log_œÉ¬≤
        encoder_output_size = hidden_size * self.num_directions
        self.fc_mu = nn.Linear(encoder_output_size, latent_dim)
        self.fc_logvar = nn.Linear(encoder_output_size, latent_dim)
        
        # ============= DECODER =============
        self.latent_to_hidden = nn.Linear(latent_dim, hidden_size)
        
        self.decoder_lstm = nn.LSTM(
            input_size=hidden_size,
            hidden_size=hidden_size,
            num_layers=num_layers,
            batch_first=True,
            dropout=dropout if num_layers > 1 else 0
        )
        
        self.fc_output = nn.Linear(hidden_size, input_size)
    
    def encode(self, x: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:
        """
        Encode l'input en param√®tres de distribution latente.
        
        Args:
            x: (batch_size, sequence_length, input_size)
        
        Returns:
            mu: (batch_size, latent_dim)
            logvar: (batch_size, latent_dim)
        """
        # LSTM encoder
        # output: (batch_size, seq_len, hidden_size * num_directions)
        # hidden: (num_layers * num_directions, batch_size, hidden_size)
        lstm_out, (hidden, cell) = self.encoder_lstm(x)
        
        # Utiliser le dernier √©tat cach√©
        if self.bidirectional:
            # Concat√©ner forward et backward du dernier layer
            hidden_last = torch.cat([hidden[-2], hidden[-1]], dim=1)
        else:
            hidden_last = hidden[-1]
        
        # Calculer Œº et log(œÉ¬≤)
        mu = self.fc_mu(hidden_last)
        logvar = self.fc_logvar(hidden_last)
        
        return mu, logvar
    
    def reparameterize(self, mu: torch.Tensor, logvar: torch.Tensor) -> torch.Tensor:
        """
        Reparameterization trick: z = Œº + œÉ * Œµ, o√π Œµ ~ N(0, 1)
        
        Args:
            mu: (batch_size, latent_dim)
            logvar: (batch_size, latent_dim)
        
        Returns:
            z: (batch_size, latent_dim)
        """
        std = torch.exp(0.5 * logvar)
        eps = torch.randn_like(std)
        z = mu + eps * std
        return z
    
    def decode(self, z: torch.Tensor) -> torch.Tensor:
        """
        D√©code z en s√©quence reconstruite.
        
        Args:
            z: (batch_size, latent_dim)
        
        Returns:
            reconstructed: (batch_size, sequence_length, input_size)
        """
        batch_size = z.size(0)
        
        # Projeter z dans l'espace du LSTM
        hidden = self.latent_to_hidden(z)  # (batch_size, hidden_size)
        hidden = torch.tanh(hidden)
        
        # R√©p√©ter pour chaque pas de temps
        # (batch_size, sequence_length, hidden_size)
        decoder_input = hidden.unsqueeze(1).repeat(1, self.sequence_length, 1)
        
        # LSTM decoder
        lstm_out, _ = self.decoder_lstm(decoder_input)
        
        # Projeter vers la dimension de sortie
        reconstructed = self.fc_output(lstm_out)
        
        return reconstructed
    
    def forward(self, x: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:
        """
        Forward pass complet du VAE.
        
        Args:
            x: (batch_size, sequence_length, input_size)
        
        Returns:
            reconstructed: (batch_size, sequence_length, input_size)
            mu: (batch_size, latent_dim)
            logvar: (batch_size, latent_dim)
        """
        # Encoder
        mu, logvar = self.encode(x)
        
        # Reparameterization
        z = self.reparameterize(mu, logvar)
        
        # Decoder
        reconstructed = self.decode(z)
        
        return reconstructed, mu, logvar
    
    def sample(self, num_samples: int, device: str = 'cpu') -> torch.Tensor:
        """
        G√©n√®re de nouvelles s√©quences en samplant l'espace latent.
        
        Args:
            num_samples: nombre de s√©quences √† g√©n√©rer
            device: 'cpu' ou 'cuda'
        
        Returns:
            samples: (num_samples, sequence_length, input_size)
        """
        with torch.no_grad():
            # Sampler z depuis N(0, 1)
            z = torch.randn(num_samples, self.latent_dim).to(device)
            
            # D√©coder
            samples = self.decode(z)
        
        return samples
    
    def count_parameters(self) -> int:
        """Compte le nombre de param√®tres entra√Ænables."""
        return sum(p.numel() for p in self.parameters() if p.requires_grad)


def get_vae_config(config_type: str = 'medium') -> dict:
    """
    Retourne une configuration pr√©d√©finie.
    
    Args:
        config_type: 'small', 'medium', 'large'
    
    Returns:
        dict avec param√®tres du mod√®le
    """
    configs = {
        'small': {
            'hidden_size': 64,
            'latent_dim': 16,
            'num_layers': 1,
            'dropout': 0.1,
            'bidirectional': False
        },
        'medium': {
            'hidden_size': 128,
            'latent_dim': 32,
            'num_layers': 2,
            'dropout': 0.2,
            'bidirectional': False
        },
        'large': {
            'hidden_size': 256,
            'latent_dim': 64,
            'num_layers': 3,
            'dropout': 0.3,
            'bidirectional': True
        }
    }
    
    return configs.get(config_type, configs['medium'])


# Test du mod√®le
if __name__ == "__main__":
    
    print("=" * 70)
    print("üß™ TEST DU LSTM-VAE")
    print("=" * 70)
    
    # Param√®tres de test
    batch_size = 16
    sequence_length = 288  # 24h avec Œît=5min
    input_size = 1
    
    # Cr√©er donn√©es de test
    x = torch.randn(batch_size, sequence_length, input_size)
    print(f"\nüìä Donn√©es de test : {x.shape}")
    
    # Tester chaque configuration
    for config_name in ['small', 'medium', 'large']:
        print(f"\n{'='*70}")
        print(f"Testing {config_name.upper()} VAE")
        print("="*70)
        
        config = get_vae_config(config_name)
        
        model = LSTMVAE(
            input_size=input_size,
            sequence_length=sequence_length,
            **config
        )
        
        n_params = model.count_parameters()
        print(f"üìä Nombre de param√®tres : {n_params:,}")
        
        # Forward pass
        x_recon, mu, logvar = model(x)
        
        print(f"‚úÖ Forward pass r√©ussi")
        print(f"   Input shape        : {x.shape}")
        print(f"   Reconstructed shape: {x_recon.shape}")
        print(f"   Mu shape           : {mu.shape}")
        print(f"   Logvar shape       : {logvar.shape}")
        
        # Test de g√©n√©ration
        samples = model.sample(num_samples=5)
        print(f"‚úÖ G√©n√©ration r√©ussie : {samples.shape}")
    
    print("\n" + "=" * 70)
    print("‚úÖ TOUS LES TESTS R√âUSSIS")
    print("=" * 70)