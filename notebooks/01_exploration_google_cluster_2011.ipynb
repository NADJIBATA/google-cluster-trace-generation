{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration du dataset Google Cluster 2011\n",
    "\n",
    "**Objectif** : Analyser les arriv√©es et √©v√©nements des jobs\n",
    "\n",
    "**Focus** : \n",
    "- `job_id` : Identifiant unique du job\n",
    "- `event_type` : Type d'√©v√©nement (SUBMIT, FINISH, FAIL, LOST, EVICT)\n",
    "- `timestamp_us` : Horodatage en microsecondes\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configuration et imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import gzip\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuration des graphiques\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (14, 6)\n",
    "plt.rcParams['font.size'] = 11\n",
    "\n",
    "print(\"‚úÖ Imports r√©ussis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. D√©finition des types d'√©v√©nements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping des event_types selon la documentation Google Cluster 2011\n",
    "EVENT_TYPES = {\n",
    "    0: 'SUBMIT',          # Job soumis au cluster\n",
    "    1: 'SCHEDULE',        # Job assign√© √† une machine\n",
    "    2: 'EVICT',           # Job expuls√© (pr√©empt√©)\n",
    "    3: 'FAIL',            # Job √©chou√©\n",
    "    4: 'FINISH',          # Job termin√© avec succ√®s\n",
    "    5: 'KILL',            # Job tu√© manuellement\n",
    "    6: 'LOST',            # Job perdu (machine crash)\n",
    "    7: 'UPDATE_PENDING',  # Mise √† jour en attente\n",
    "    8: 'UPDATE_RUNNING'   # Mise √† jour pendant ex√©cution\n",
    "}\n",
    "\n",
    "# Colonnes du dataset\n",
    "COLUMNS = [\n",
    "    'timestamp',           # Microsecondes depuis epoch\n",
    "    'missing_info',        # Bitmap d'info manquante\n",
    "    'job_id',             # ID unique du job\n",
    "    'event_type',         # Type d'√©v√©nement (0-8)\n",
    "    'user',               # Hash de l'utilisateur\n",
    "    'scheduling_class',   # Classe de scheduling (0-3)\n",
    "    'job_name',           # Hash du nom du job\n",
    "    'logical_job_name'    # Hash du nom logique\n",
    "]\n",
    "\n",
    "print(\"Event types disponibles:\")\n",
    "for code, name in EVENT_TYPES.items():\n",
    "    print(f\"  {code}: {name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Chargement des donn√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trouver les fichiers\n",
    "data_dir = Path('data/raw/2011')\n",
    "files = sorted(data_dir.glob('part-*.csv.gz'))\n",
    "\n",
    "print(f\"üìÅ Dossier: {data_dir}\")\n",
    "print(f\"üìä Fichiers trouv√©s: {len(files)}\")\n",
    "\n",
    "if len(files) == 0:\n",
    "    print(\"\\n‚ùå ERREUR: Aucun fichier trouv√©!\")\n",
    "    print(\"V√©rifiez que les fichiers part-*.csv.gz sont dans data/raw/2011/\")\n",
    "else:\n",
    "    print(f\"\\n‚úÖ Premiers fichiers:\")\n",
    "    for f in files[:5]:\n",
    "        size_mb = f.stat().st_size / (1024 * 1024)\n",
    "        print(f\"  ‚Ä¢ {f.name} ({size_mb:.1f} MB)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Inspection du format d'un fichier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspecter le premier fichier\n",
    "if files:\n",
    "    first_file = files[0]\n",
    "    print(f\"üîç Inspection de: {first_file.name}\\n\")\n",
    "    \n",
    "    with gzip.open(first_file, 'rt') as f:\n",
    "        for i, line in enumerate(f):\n",
    "            if i >= 3:\n",
    "                break\n",
    "            print(f\"Ligne {i}:\")\n",
    "            print(f\"  {line.strip()[:200]}\")\n",
    "            print(f\"  ‚Üí Virgules: {line.count(',')}, Longueur: {len(line.strip())}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Chargement d'un √©chantillon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_sample(filepath, n_rows=10000):\n",
    "    \"\"\"\n",
    "    Charge un √©chantillon d'un fichier.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with gzip.open(filepath, 'rt') as f:\n",
    "            df = pd.read_csv(\n",
    "                f,\n",
    "                header=None,\n",
    "                names=COLUMNS,\n",
    "                usecols=['timestamp', 'job_id', 'event_type'],\n",
    "                dtype={\n",
    "                    'timestamp': 'int64',\n",
    "                    'job_id': 'int64',\n",
    "                    'event_type': 'int32'\n",
    "                },\n",
    "                nrows=n_rows,\n",
    "                sep=',',\n",
    "                on_bad_lines='skip'\n",
    "            )\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erreur: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# Charger un √©chantillon du premier fichier\n",
    "print(\"Chargement d'un √©chantillon (10,000 lignes)...\")\n",
    "df_sample = load_sample(files[0])\n",
    "\n",
    "print(f\"\\n‚úÖ Charg√©: {len(df_sample):,} lignes\")\n",
    "print(f\"\\nColonnes: {df_sample.columns.tolist()}\")\n",
    "print(f\"\\nTypes de donn√©es:\")\n",
    "print(df_sample.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Afficher les premi√®res lignes\n",
    "print(\"üìä Premi√®res lignes du dataset:\\n\")\n",
    "df_sample.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Conversion des timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir timestamp en datetime\n",
    "df_sample['datetime'] = pd.to_datetime(df_sample['timestamp'], unit='us', errors='coerce')\n",
    "\n",
    "# Ajouter le nom de l'event_type\n",
    "df_sample['event_name'] = df_sample['event_type'].map(EVENT_TYPES)\n",
    "\n",
    "print(\"‚úÖ Conversion des timestamps termin√©e\\n\")\n",
    "print(f\"P√©riode couverte:\")\n",
    "print(f\"  D√©but: {df_sample['datetime'].min()}\")\n",
    "print(f\"  Fin:   {df_sample['datetime'].max()}\")\n",
    "print(f\"  Dur√©e: {df_sample['datetime'].max() - df_sample['datetime'].min()}\")\n",
    "\n",
    "# Afficher avec datetime\n",
    "df_sample[['job_id', 'event_type', 'event_name', 'timestamp', 'datetime']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Analyse des event_types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Distribution des types d'√©v√©nements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compter les √©v√©nements par type\n",
    "event_counts = df_sample['event_type'].value_counts().sort_index()\n",
    "\n",
    "print(\"Distribution des √©v√©nements:\\n\")\n",
    "print(\"=\"*60)\n",
    "for event_type, count in event_counts.items():\n",
    "    event_name = EVENT_TYPES.get(event_type, 'UNKNOWN')\n",
    "    percentage = count / len(df_sample) * 100\n",
    "    print(f\"{event_type} - {event_name:20s}: {count:>8,} ({percentage:>5.2f}%)\")\n",
    "print(\"=\"*60)\n",
    "print(f\"TOTAL: {len(df_sample):,} √©v√©nements\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation de la distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Graphique √† barres\n",
    "ax1 = axes[0]\n",
    "event_names = [EVENT_TYPES[e] for e in event_counts.index]\n",
    "colors = sns.color_palette(\"husl\", len(event_counts))\n",
    "\n",
    "bars = ax1.bar(event_names, event_counts.values, color=colors, edgecolor='black', linewidth=1.5)\n",
    "ax1.set_title('Distribution des types d\\'√©v√©nements', fontsize=14, fontweight='bold')\n",
    "ax1.set_xlabel('Type d\\'√©v√©nement')\n",
    "ax1.set_ylabel('Nombre d\\'√©v√©nements')\n",
    "ax1.tick_params(axis='x', rotation=45)\n",
    "ax1.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Ajouter les valeurs sur les barres\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    ax1.text(bar.get_x() + bar.get_width()/2., height,\n",
    "            f'{int(height):,}',\n",
    "            ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "# Camembert\n",
    "ax2 = axes[1]\n",
    "wedges, texts, autotexts = ax2.pie(\n",
    "    event_counts.values,\n",
    "    labels=event_names,\n",
    "    autopct='%1.1f%%',\n",
    "    colors=colors,\n",
    "    startangle=90,\n",
    "    textprops={'fontsize': 10}\n",
    ")\n",
    "ax2.set_title('Proportion des √©v√©nements', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('results/figures/event_type_distribution.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Figure sauvegard√©e: results/figures/event_type_distribution.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Focus sur les √©v√©nements cl√©s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraire les √©v√©nements principaux\n",
    "submit_events = df_sample[df_sample['event_type'] == 0]  # SUBMIT\n",
    "finish_events = df_sample[df_sample['event_type'] == 4]  # FINISH\n",
    "fail_events = df_sample[df_sample['event_type'] == 3]    # FAIL\n",
    "evict_events = df_sample[df_sample['event_type'] == 2]   # EVICT\n",
    "lost_events = df_sample[df_sample['event_type'] == 6]    # LOST\n",
    "\n",
    "print(\"√âv√©nements cl√©s:\\n\")\n",
    "print(f\"üì• SUBMIT (arriv√©es):  {len(submit_events):>8,} √©v√©nements\")\n",
    "print(f\"‚úÖ FINISH (succ√®s):    {len(finish_events):>8,} √©v√©nements\")\n",
    "print(f\"‚ùå FAIL (√©checs):      {len(fail_events):>8,} √©v√©nements\")\n",
    "print(f\"‚è∏Ô∏è  EVICT (pr√©emption): {len(evict_events):>8,} √©v√©nements\")\n",
    "print(f\"üíî LOST (perdus):      {len(lost_events):>8,} √©v√©nements\")\n",
    "\n",
    "# Taux de r√©ussite/√©chec\n",
    "if len(submit_events) > 0:\n",
    "    success_rate = len(finish_events) / len(submit_events) * 100\n",
    "    failure_rate = len(fail_events) / len(submit_events) * 100\n",
    "    eviction_rate = len(evict_events) / len(submit_events) * 100\n",
    "    \n",
    "    print(f\"\\nüìä Statistiques (par rapport aux SUBMIT):\")\n",
    "    print(f\"  Taux de succ√®s:    {success_rate:>6.2f}%\")\n",
    "    print(f\"  Taux d'√©chec:      {failure_rate:>6.2f}%\")\n",
    "    print(f\"  Taux de pr√©emption: {eviction_rate:>6.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Analyse des arriv√©es de jobs (SUBMIT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 S√©rie temporelle des arriv√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraire les arriv√©es\n",
    "arrivals = df_sample[df_sample['event_type'] == 0].copy()\n",
    "arrivals = arrivals.sort_values('timestamp')\n",
    "\n",
    "print(f\"üì• Arriv√©es de jobs: {len(arrivals):,}\")\n",
    "print(f\"   Jobs uniques: {arrivals['job_id'].nunique():,}\")\n",
    "print(f\"   P√©riode: {arrivals['datetime'].min()} ‚Üí {arrivals['datetime'].max()}\")\n",
    "\n",
    "# Afficher quelques arriv√©es\n",
    "arrivals[['job_id', 'timestamp', 'datetime']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compter les arriv√©es par diff√©rents intervalles de temps\n",
    "arrivals_1min = arrivals.set_index('datetime').resample('1min').size()\n",
    "arrivals_10min = arrivals.set_index('datetime').resample('10min').size()\n",
    "arrivals_1h = arrivals.set_index('datetime').resample('1H').size()\n",
    "\n",
    "print(\"Statistiques des arriv√©es:\\n\")\n",
    "\n",
    "print(\"Par minute:\")\n",
    "print(f\"  Moyenne: {arrivals_1min.mean():.2f}\")\n",
    "print(f\"  M√©diane: {arrivals_1min.median():.2f}\")\n",
    "print(f\"  Max:     {arrivals_1min.max():.0f}\")\n",
    "\n",
    "print(\"\\nPar 10 minutes:\")\n",
    "print(f\"  Moyenne: {arrivals_10min.mean():.2f}\")\n",
    "print(f\"  M√©diane: {arrivals_10min.median():.2f}\")\n",
    "print(f\"  Max:     {arrivals_10min.max():.0f}\")\n",
    "\n",
    "print(\"\\nPar heure:\")\n",
    "print(f\"  Moyenne: {arrivals_1h.mean():.2f}\")\n",
    "print(f\"  M√©diane: {arrivals_1h.median():.2f}\")\n",
    "print(f\"  Max:     {arrivals_1h.max():.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation des arriv√©es\n",
    "fig, axes = plt.subplots(3, 1, figsize=(16, 12))\n",
    "\n",
    "# Par minute\n",
    "ax1 = axes[0]\n",
    "arrivals_1min.plot(ax=ax1, linewidth=0.8, color='steelblue', alpha=0.7)\n",
    "ax1.set_title('Arriv√©es de jobs par minute', fontsize=13, fontweight='bold')\n",
    "ax1.set_ylabel('Nombre de jobs')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.axhline(arrivals_1min.mean(), color='red', linestyle='--', \n",
    "           label=f'Moyenne: {arrivals_1min.mean():.1f}', alpha=0.7)\n",
    "ax1.legend()\n",
    "\n",
    "# Par 10 minutes\n",
    "ax2 = axes[1]\n",
    "arrivals_10min.plot(ax=ax2, linewidth=1.2, color='coral', alpha=0.8)\n",
    "ax2.set_title('Arriv√©es de jobs par 10 minutes', fontsize=13, fontweight='bold')\n",
    "ax2.set_ylabel('Nombre de jobs')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.axhline(arrivals_10min.mean(), color='red', linestyle='--',\n",
    "           label=f'Moyenne: {arrivals_10min.mean():.1f}', alpha=0.7)\n",
    "ax2.legend()\n",
    "\n",
    "# Par heure\n",
    "ax3 = axes[2]\n",
    "arrivals_1h.plot(ax=ax3, linewidth=1.5, color='mediumseagreen', alpha=0.8, marker='o', markersize=4)\n",
    "ax3.set_title('Arriv√©es de jobs par heure', fontsize=13, fontweight='bold')\n",
    "ax3.set_xlabel('Temps')\n",
    "ax3.set_ylabel('Nombre de jobs')\n",
    "ax3.grid(True, alpha=0.3)\n",
    "ax3.axhline(arrivals_1h.mean(), color='red', linestyle='--',\n",
    "           label=f'Moyenne: {arrivals_1h.mean():.1f}', alpha=0.7)\n",
    "ax3.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('results/figures/arrivals_temporal_series.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Figure sauvegard√©e: results/figures/arrivals_temporal_series.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Histogramme des arriv√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Histogramme par minute\n",
    "ax1 = axes[0]\n",
    "arrivals_1min[arrivals_1min > 0].hist(bins=50, ax=ax1, color='steelblue', \n",
    "                                       edgecolor='black', alpha=0.7)\n",
    "ax1.set_title('Distribution des arriv√©es par minute', fontsize=13, fontweight='bold')\n",
    "ax1.set_xlabel('Nombre d\\'arriv√©es')\n",
    "ax1.set_ylabel('Fr√©quence')\n",
    "ax1.grid(True, alpha=0.3, axis='y')\n",
    "ax1.axvline(arrivals_1min.mean(), color='red', linestyle='--', \n",
    "           label=f'Moyenne: {arrivals_1min.mean():.1f}', linewidth=2)\n",
    "ax1.legend()\n",
    "\n",
    "# Histogramme par heure\n",
    "ax2 = axes[1]\n",
    "arrivals_1h[arrivals_1h > 0].hist(bins=30, ax=ax2, color='coral',\n",
    "                                  edgecolor='black', alpha=0.7)\n",
    "ax2.set_title('Distribution des arriv√©es par heure', fontsize=13, fontweight='bold')\n",
    "ax2.set_xlabel('Nombre d\\'arriv√©es')\n",
    "ax2.set_ylabel('Fr√©quence')\n",
    "ax2.grid(True, alpha=0.3, axis='y')\n",
    "ax2.axvline(arrivals_1h.mean(), color='red', linestyle='--',\n",
    "           label=f'Moyenne: {arrivals_1h.mean():.1f}', linewidth=2)\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('results/figures/arrivals_histograms.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Figure sauvegard√©e: results/figures/arrivals_histograms.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Pattern journalier et hebdomadaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraire les composantes temporelles\n",
    "arrivals['hour'] = arrivals['datetime'].dt.hour\n",
    "arrivals['day_of_week'] = arrivals['datetime'].dt.dayofweek\n",
    "arrivals['date'] = arrivals['datetime'].dt.date\n",
    "\n",
    "# Pattern horaire\n",
    "hourly_pattern = arrivals.groupby('hour').size()\n",
    "\n",
    "# Pattern hebdomadaire\n",
    "days = ['Lundi', 'Mardi', 'Mercredi', 'Jeudi', 'Vendredi', 'Samedi', 'Dimanche']\n",
    "weekly_pattern = arrivals.groupby('day_of_week').size()\n",
    "\n",
    "print(\"Pattern journalier (par heure):\\n\")\n",
    "for hour, count in hourly_pattern.items():\n",
    "    print(f\"  {hour:2d}h: {count:>6,} arriv√©es\")\n",
    "\n",
    "print(\"\\nPattern hebdomadaire:\\n\")\n",
    "for day_idx, count in weekly_pattern.items():\n",
    "    print(f\"  {days[day_idx]:10s}: {count:>6,} arriv√©es\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Pattern horaire\n",
    "ax1 = axes[0]\n",
    "hourly_pattern.plot(kind='bar', ax=ax1, color='steelblue', \n",
    "                    edgecolor='black', width=0.8)\n",
    "ax1.set_title('Pattern journalier - Arriv√©es par heure', \n",
    "             fontsize=13, fontweight='bold')\n",
    "ax1.set_xlabel('Heure de la journ√©e')\n",
    "ax1.set_ylabel('Nombre total d\\'arriv√©es')\n",
    "ax1.set_xticklabels(range(24), rotation=0)\n",
    "ax1.grid(True, alpha=0.3, axis='y')\n",
    "ax1.axhline(hourly_pattern.mean(), color='red', linestyle='--',\n",
    "           label=f'Moyenne: {hourly_pattern.mean():.0f}', alpha=0.7)\n",
    "ax1.legend()\n",
    "\n",
    "# Pattern hebdomadaire\n",
    "ax2 = axes[1]\n",
    "weekly_pattern.plot(kind='bar', ax=ax2, color='coral',\n",
    "                   edgecolor='black', width=0.8)\n",
    "ax2.set_title('Pattern hebdomadaire - Arriv√©es par jour',\n",
    "             fontsize=13, fontweight='bold')\n",
    "ax2.set_xlabel('Jour de la semaine')\n",
    "ax2.set_ylabel('Nombre total d\\'arriv√©es')\n",
    "ax2.set_xticklabels(days, rotation=45, ha='right')\n",
    "ax2.grid(True, alpha=0.3, axis='y')\n",
    "ax2.axhline(weekly_pattern.mean(), color='red', linestyle='--',\n",
    "           label=f'Moyenne: {weekly_pattern.mean():.0f}', alpha=0.7)\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('results/figures/arrivals_patterns.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Figure sauvegard√©e: results/figures/arrivals_patterns.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Heatmap jour √ó heure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cr√©er une matrice jour √ó heure\n",
    "daily_hourly = arrivals.groupby(['date', 'hour']).size().reset_index(name='count')\n",
    "pivot_table = daily_hourly.pivot_table(values='count', \n",
    "                                       index='date', \n",
    "                                       columns='hour',\n",
    "                                       fill_value=0)\n",
    "\n",
    "# Limiter aux premiers jours pour lisibilit√©\n",
    "n_days = min(30, len(pivot_table))\n",
    "pivot_subset = pivot_table.iloc[:n_days]\n",
    "\n",
    "# Heatmap\n",
    "fig, ax = plt.subplots(figsize=(16, 10))\n",
    "\n",
    "sns.heatmap(pivot_subset, \n",
    "           cmap='YlOrRd',\n",
    "           ax=ax,\n",
    "           cbar_kws={'label': 'Nombre d\\'arriv√©es'},\n",
    "           linewidths=0.5,\n",
    "           linecolor='white')\n",
    "\n",
    "ax.set_title(f'Heatmap des arriv√©es (jour √ó heure) - {n_days} premiers jours',\n",
    "            fontsize=14, fontweight='bold', pad=20)\n",
    "ax.set_xlabel('Heure de la journ√©e', fontsize=12)\n",
    "ax.set_ylabel('Date', fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('results/figures/arrivals_heatmap.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Figure sauvegard√©e: results/figures/arrivals_heatmap.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Analyse du cycle de vie des jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Tracer quelques jobs individuels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jobs qui ont plusieurs √©v√©nements\n",
    "job_event_counts = df_sample.groupby('job_id').size()\n",
    "jobs_with_multiple_events = job_event_counts[job_event_counts > 1].index[:10]\n",
    "\n",
    "print(f\"Jobs avec plusieurs √©v√©nements (10 premiers):\\n\")\n",
    "\n",
    "for job_id in jobs_with_multiple_events:\n",
    "    job_events = df_sample[df_sample['job_id'] == job_id].sort_values('timestamp')\n",
    "    \n",
    "    print(f\"\\nJob {job_id}:\")\n",
    "    for _, event in job_events.iterrows():\n",
    "        event_name = EVENT_TYPES[event['event_type']]\n",
    "        print(f\"  {event['datetime']} - {event_name}\")\n",
    "    \n",
    "    # Dur√©e totale\n",
    "    duration = job_events['datetime'].max() - job_events['datetime'].min()\n",
    "    print(f\"  Dur√©e totale: {duration}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Statistiques des transitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyser les transitions d'√©v√©nements\n",
    "df_sorted = df_sample.sort_values(['job_id', 'timestamp'])\n",
    "df_sorted['next_event'] = df_sorted.groupby('job_id')['event_type'].shift(-1)\n",
    "\n",
    "# Supprimer les NaN (derniers √©v√©nements de chaque job)\n",
    "transitions = df_sorted.dropna(subset=['next_event'])\n",
    "transitions['next_event'] = transitions['next_event'].astype(int)\n",
    "\n",
    "# Cr√©er une matrice de transition\n",
    "transition_matrix = pd.crosstab(\n",
    "    transitions['event_type'].map(EVENT_TYPES),\n",
    "    transitions['next_event'].map(EVENT_TYPES),\n",
    "    normalize='index'\n",
    ") * 100\n",
    "\n",
    "print(\"Matrice de transition (% de probabilit√©):\\n\")\n",
    "print(transition_matrix.round(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap des transitions\n",
    "fig, ax = plt.subplots(figsize=(12, 10))\n",
    "\n",
    "sns.heatmap(transition_matrix,\n",
    "           annot=True,\n",
    "           fmt='.1f',\n",
    "           cmap='YlGnBu',\n",
    "           ax=ax,\n",
    "           cbar_kws={'label': 'Probabilit√© (%)'},\n",
    "           linewidths=1,\n",
    "           linecolor='white')\n",
    "\n",
    "ax.set_title('Matrice de transition des √©v√©nements',\n",
    "            fontsize=14, fontweight='bold', pad=20)\n",
    "ax.set_xlabel('√âv√©nement suivant', fontsize=12)\n",
    "ax.set_ylabel('√âv√©nement actuel', fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('results/figures/transition_matrix.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Figure sauvegard√©e: results/figures/transition_matrix.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Chargement de plusieurs fichiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_multiple_files(files, max_files=10, rows_per_file=50000):\n",
    "    \"\"\"\n",
    "    Charge plusieurs fichiers et consolide.\n",
    "    \"\"\"\n",
    "    all_data = []\n",
    "    \n",
    "    print(f\"Chargement de {max_files} fichiers ({rows_per_file:,} lignes par fichier)...\\n\")\n",
    "    \n",
    "    for i, filepath in enumerate(files[:max_files], 1):\n",
    "        print(f\"[{i}/{max_files}] {filepath.name}\")\n",
    "        \n",
    "        df = load_sample(filepath, n_rows=rows_per_file)\n",
    "        \n",
    "        if not df.empty:\n",
    "            all_data.append(df)\n",
    "            print(f\"  ‚úì {len(df):,} lignes charg√©es\")\n",
    "    \n",
    "    # Consolider\n",
    "    print(\"\\nConsolidation...\")\n",
    "    result = pd.concat(all_data, ignore_index=True)\n",
    "    \n",
    "    # Convertir timestamps\n",
    "    result['datetime'] = pd.to_datetime(result['timestamp'], unit='us', errors='coerce')\n",
    "    result['event_name'] = result['event_type'].map(EVENT_TYPES)\n",
    "    \n",
    "    print(f\"\\n‚úÖ Total: {len(result):,} √©v√©nements\")\n",
    "    print(f\"   Jobs uniques: {result['job_id'].nunique():,}\")\n",
    "    print(f\"   P√©riode: {result['datetime'].min()} ‚Üí {result['datetime'].max()}\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Charger 10 fichiers\n",
    "df_large = load_multiple_files(files, max_files=10, rows_per_file=50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistiques sur le dataset √©largi\n",
    "print(\"Statistiques du dataset √©largi:\\n\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total √©v√©nements:     {len(df_large):>12,}\")\n",
    "print(f\"Jobs uniques:         {df_large['job_id'].nunique():>12,}\")\n",
    "print(f\"P√©riode:              {df_large['datetime'].min()}\")\n",
    "print(f\"                   ‚Üí {df_large['datetime'].max()}\")\n",
    "print(f\"Dur√©e:                {df_large['datetime'].max() - df_large['datetime'].min()}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nDistribution des √©v√©nements:\\n\")\n",
    "event_dist = df_large['event_name'].value_counts()\n",
    "for event_name, count in event_dist.items():\n",
    "    pct = count / len(df_large) * 100\n",
    "    print(f\"  {event_name:20s}: {count:>12,} ({pct:>5.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Sauvegarde des arriv√©es pour analyse ult√©rieure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraire et sauvegarder les arriv√©es\n",
    "arrivals_large = df_large[df_large['event_type'] == 0].copy()\n",
    "arrivals_large = arrivals_large.sort_values('timestamp')\n",
    "\n",
    "# Sauvegarder\n",
    "output_path = 'data/processed/2011_arrivals_sample.csv'\n",
    "arrivals_large[['job_id', 'timestamp', 'datetime']].to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"‚úÖ Arriv√©es sauvegard√©es: {output_path}\")\n",
    "print(f\"   {len(arrivals_large):,} arriv√©es\")\n",
    "print(f\"   {arrivals_large['job_id'].nunique():,} jobs uniques\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. R√©sum√© et conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"R√âSUM√â DE L'EXPLORATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nüìä Dataset:\")\n",
    "print(f\"  ‚Ä¢ Fichiers analys√©s: {len(files)} disponibles\")\n",
    "print(f\"  ‚Ä¢ √âv√©nements charg√©s: {len(df_large):,}\")\n",
    "print(f\"  ‚Ä¢ Jobs uniques: {df_large['job_id'].nunique():,}\")\n",
    "\n",
    "print(\"\\nüì• Arriv√©es (SUBMIT):\")\n",
    "arrivals_stats = arrivals_large.set_index('datetime').resample('1H').size()\n",
    "print(f\"  ‚Ä¢ Total arriv√©es: {len(arrivals_large):,}\")\n",
    "print(f\"  ‚Ä¢ Moyenne/heure: {arrivals_stats.mean():.2f}\")\n",
    "print(f\"  ‚Ä¢ Max/heure: {arrivals_stats.max():.0f}\")\n",
    "\n",
    "print(\"\\nüéØ Types d'√©v√©nements:\")\n",
    "for event_name in ['SUBMIT', 'FINISH', 'FAIL', 'EVICT']:\n",
    "    count = (df_large['event_name'] == event_name).sum()\n",
    "    pct = count / len(df_large) * 100\n",
    "    print(f\"  ‚Ä¢ {event_name:10s}: {count:>10,} ({pct:>5.2f}%)\")\n",
    "\n",
    "print(\"\\nüíæ Fichiers g√©n√©r√©s:\")\n",
    "print(\"  ‚Ä¢ results/figures/event_type_distribution.png\")\n",
    "print(\"  ‚Ä¢ results/figures/arrivals_temporal_series.png\")\n",
    "print(\"  ‚Ä¢ results/figures/arrivals_histograms.png\")\n",
    "print(\"  ‚Ä¢ results/figures/arrivals_patterns.png\")\n",
    "print(\"  ‚Ä¢ results/figures/arrivals_heatmap.png\")\n",
    "print(\"  ‚Ä¢ results/figures/transition_matrix.png\")\n",
    "print(\"  ‚Ä¢ data/processed/2011_arrivals_sample.csv\")\n",
    "\n",
    "print(\"\\nüöÄ Prochaines √©tapes:\")\n",
    "print(\"  1. Charger tous les fichiers (500) pour dataset complet\")\n",
    "print(\"  2. Cr√©er les s√©quences temporelles pour le VAE\")\n",
    "print(\"  3. Analyser l'incertitude (bo√Ætes, polytopes, Wasserstein)\")\n",
    "print(\"  4. Entra√Æner le mod√®le VAE-LSTM\")\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
